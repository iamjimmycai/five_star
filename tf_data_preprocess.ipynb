{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG5qqRxg9hwCEfeHC0K7gp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5560d688bca942ccb41baf2251ae7a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9ea8d1e80874ad282e767af6255ef60",
              "IPY_MODEL_815e710e4f74461e8271da66dbf863d1",
              "IPY_MODEL_26b53504d9d843e8b19b874251c73fa2"
            ],
            "layout": "IPY_MODEL_0ec2b7a8480e481896c12c59cd75f8c8"
          }
        },
        "c9ea8d1e80874ad282e767af6255ef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d169cc281a846ab883b551aae5f28c8",
            "placeholder": "​",
            "style": "IPY_MODEL_5f97f154c59d4d36ae0bbc55353ac36c",
            "value": "Dl Completed...: 100%"
          }
        },
        "815e710e4f74461e8271da66dbf863d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1c99005a7a4fd48e8377197bf23af2",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ae5ecf517394bdabb6e53cf897de938",
            "value": 5
          }
        },
        "26b53504d9d843e8b19b874251c73fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88cd0db5d4c84f5fb11d6fb1beb906dc",
            "placeholder": "​",
            "style": "IPY_MODEL_5b02d642f9d94f32ad2f7edf6212b6c3",
            "value": " 5/5 [00:05&lt;00:00,  1.31s/ file]"
          }
        },
        "0ec2b7a8480e481896c12c59cd75f8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d169cc281a846ab883b551aae5f28c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f97f154c59d4d36ae0bbc55353ac36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1c99005a7a4fd48e8377197bf23af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae5ecf517394bdabb6e53cf897de938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88cd0db5d4c84f5fb11d6fb1beb906dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b02d642f9d94f32ad2f7edf6212b6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamjimmycai/five_star/blob/main/tf_data_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# extra code – for reproducibility\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "JTHecPUKpkjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tf.data.Dataset"
      ],
      "metadata": {
        "id": "jR3nf5bprNj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oVx_8T6pVmr",
        "outputId": "3f38fc90-ccbe-4c02-bf78-b0b3d04ccd24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "X = tf.range(10)  # any data tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXSeYSjupqSp",
        "outputId": "8f0e79d1-bbb8-4480-e97b-92e163155252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgFHFPAVp1z6",
        "outputId": "b7325df3-2b1c-4a77-b6e3-c3d6f7dc5f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
            "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3icdw1MDqDYP",
        "outputId": "e0aa375d-a365-47a5-91e1-c6feceff18ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda x: x * 2)  # x is a batch\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCRjjtb4qNgv",
        "outputId": "63aa00cc-4c83-4e01-e652-b39850db34e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DsG_n-cqbrh",
        "outputId": "6a47ee54-31d7-45ec-8522-e6b3c00b69d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in dataset.take(2):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfoCvNr4qe6G",
        "outputId": "533a8b5d-330f-498f-e2d4-bd964ee52b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(2)\n",
        "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhW_tdx8qkzd",
        "outputId": "1a933a46-0206-476e-e122-4b1dfbd5ba69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read multiple files parallel"
      ],
      "metadata": {
        "id": "n8Y5F10frX2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def save_to_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = Path() / \"datasets\" / \"housing\"\n",
        "    housing_dir.mkdir(parents=True, exist_ok=True)\n",
        "    filename_format = \"my_{}_{:02d}.csv\"\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    chunks = np.array_split(np.arange(m), n_parts)\n",
        "    for file_idx, row_indices in enumerate(chunks):\n",
        "        part_csv = housing_dir / filename_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(str(part_csv))\n",
        "        with open(part_csv, \"w\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths\n",
        "\n",
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "metadata": {
        "id": "uHHpYKE4qrCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\".join(open(train_filepaths[0]).readlines()[:4]))\n",
        "# train_filepaths\n",
        "\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
        "# extra code – shows that the file paths are shuffled\n",
        "for filepath in filepath_dataset:\n",
        "    print(filepath)\n",
        "\n",
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers)\n",
        "for line in dataset.take(5):\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biOgNQ2GrRUR",
        "outputId": "a868d2a7-9d6b-44ae-c179-98aa3eca8b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418', shape=(), dtype=string)\n",
            "tf.Tensor(b'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0', shape=(), dtype=string)\n",
            "tf.Tensor(b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67', shape=(), dtype=string)\n",
            "tf.Tensor(b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205', shape=(), dtype=string)\n",
            "tf.Tensor(b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_mean, X_std = scaler.mean_, scaler.scale_  # extra code\n",
        "n_inputs = 8\n",
        "\n",
        "def parse_csv_line(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n",
        "\n",
        "def preprocess(line):\n",
        "    x, y = parse_csv_line(line)\n",
        "    return (x - X_mean) / X_std, y\n",
        "\n",
        "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIyuoXtYr-Wq",
        "outputId": "0e0b1cbf-2739-45ec-d170-b4b5ea3688e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
              "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting Everything Together + Prefetching\n",
        "def csv_reader_dataset(filepaths, n_readers=5, n_read_threads=None,\n",
        "                       n_parse_threads=5, shuffle_buffer_size=10_000, seed=42,\n",
        "                       batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
        "    return dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "example_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
        "for X_batch, y_batch in example_set.take(2):\n",
        "    print(\"X =\", X_batch)\n",
        "    print(\"y =\", y_batch)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TASzaY6Ws8MS",
        "outputId": "cba7090b-4659-4acd-f6f7-643c86e84933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = tf.Tensor(\n",
            "[[-1.3957452  -0.04940685 -0.22830808  0.22648273  2.2593622   0.35200632\n",
            "   0.9667386  -1.4121602 ]\n",
            " [ 2.7112627  -1.0778131   0.69413143 -0.14870553  0.51810503  0.3507294\n",
            "  -0.82285154  0.80680597]\n",
            " [-0.13484643 -1.868895    0.01032507 -0.13787179 -0.12893449  0.03143518\n",
            "   0.2687057   0.13212144]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[1.819]\n",
            " [3.674]\n",
            " [0.954]], shape=(3, 1), dtype=float32)\n",
            "\n",
            "X = tf.Tensor(\n",
            "[[ 0.09031774  0.9789995   0.1327582  -0.13753782 -0.23388447  0.10211545\n",
            "   0.97610843 -1.4121602 ]\n",
            " [ 0.05218809 -2.0271113   0.2940109  -0.02403445  0.16218767 -0.02844518\n",
            "   1.4117942  -0.93737936]\n",
            " [-0.672276    0.02970133 -0.76922584 -0.15086786  0.4962024  -0.02741998\n",
            "  -0.7853724   0.77182245]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[2.725]\n",
            " [1.205]\n",
            " [1.625]], shape=(3, 1), dtype=float32)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for m in dir(tf.data.Dataset):\n",
        "#     if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
        "#         func = getattr(tf.data.Dataset, m)\n",
        "#         if hasattr(func, \"__doc__\"):\n",
        "#             print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
      ],
      "metadata": {
        "id": "qH0RuCiitP_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Dataset with Keras\n"
      ],
      "metadata": {
        "id": "Ra0BVtZttnL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                          input_shape=X_train.shape[1:]),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
        "model.fit(train_set, validation_data=valid_set, epochs=5)\n",
        "test_mse = model.evaluate(test_set)\n",
        "new_set = test_set.take(3)  # pretend we have 3 new samples\n",
        "y_pred = model.predict(new_set)  # or you could just pass a NumPy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85Tbw9ftcam",
        "outputId": "b5bf3bdc-09a3-4887-8d06-72deb89c60ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "    363/Unknown \u001b[1m5s\u001b[0m 5ms/step - loss: 4.5854"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 4.5838 - val_loss: 0.5752\n",
            "Epoch 2/5\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.6182 - val_loss: 0.4084\n",
            "Epoch 3/5\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4300 - val_loss: 0.3822\n",
            "Epoch 4/5\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.4100 - val_loss: 0.3717\n",
            "Epoch 5/5\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3812 - val_loss: 0.3660\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3847\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The TFRecord Format"
      ],
      "metadata": {
        "id": "arhvhIghupgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")"
      ],
      "metadata": {
        "id": "oFP0BunVufSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0CzObKLuscm",
        "outputId": "7f1d4656-1619-4a97-f82b-0dfb7df5876f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"my_test_{}.tfrecord\".format(i) for i in range(5)]\n",
        "for i, filepath in enumerate(filepaths):\n",
        "    with tf.io.TFRecordWriter(filepath) as f:\n",
        "        for j in range(3):\n",
        "            f.write(\"File {} record {}\".format(i, j).encode(\"utf-8\"))\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AFgvAlKu0XT",
        "outputId": "b8c2d285-4e2e-4ac5-d9e8-4b6c64dcc9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'File 0 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 0 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 0 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 1 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 2 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 0', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 1', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 3 record 2', shape=(), dtype=string)\n",
            "tf.Tensor(b'File 4 record 2', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
        "    f.write(b\"Compress, compress, compress!\")"
      ],
      "metadata": {
        "id": "auqx3o65u_0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
        "                                  compression_type=\"GZIP\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ06EZ-3vH2v",
        "outputId": "97c9a56c-83be-44c3-94f2-82a638b2561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Compress, compress, compress!', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Discretization Layer\n"
      ],
      "metadata": {
        "id": "A7YUsjWDvoZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])\n",
        "discretize_layer = tf.keras.layers.Discretization(bin_boundaries=[18., 50.])\n",
        "age_categories = discretize_layer(age)\n",
        "age_categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJmdWNxBvN3p",
        "outputId": "a5b9c6e0-53ba-43f8-d5da-b42728a2fc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\n",
              "array([[0],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discretize_layer = tf.keras.layers.Discretization(num_bins=3)\n",
        "discretize_layer.adapt(age)\n",
        "age_categories = discretize_layer(age)\n",
        "age_categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITiS12tXvstA",
        "outputId": "75f9f722-d9df-4ec1-fe55-d1e9b890796e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\n",
              "array([[1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The CategoryEncoding Layer\n"
      ],
      "metadata": {
        "id": "WAcbBBQ_v3qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\n",
        "onehot_layer(age_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lmnhOB7vyFc",
        "outputId": "9cda6861-f5fe-4a29-9da7-3589bca76a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_age_categories = np.array([[1, 0], [2, 2], [2, 0]])\n",
        "onehot_layer(two_age_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EPfaHMXv9Fa",
        "outputId": "e3687e16-2797-4770-a660-459e5e9f1df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3, output_mode=\"count\")\n",
        "onehot_layer(two_age_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjcAvyViwBlO",
        "outputId": "4245c26e-5e07-40b7-d1a9-0be4f0bc8b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 1., 0.],\n",
              "       [0., 0., 2.],\n",
              "       [1., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3 + 3)\n",
        "# onehot_layer(two_age_categories + [0, 3])  # adds 3 to the second feature\n",
        "\n",
        "# # extra code – shows another way to one-hot encode each feature separately\n",
        "# onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3,\n",
        "#                                                 output_mode=\"one_hot\")\n",
        "# tf.keras.layers.concatenate([onehot_layer(cat)\n",
        "#                              for cat in tf.transpose(two_age_categories)])\n",
        "\n",
        "# extra code – shows another way to do this, using tf.one_hot() and Flatten\n",
        "tf.keras.layers.Flatten()(tf.one_hot(two_age_categories, depth=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWDQB74FwQEO",
        "outputId": "33b1074c-95f0-46d7-9a7b-87a627fd7b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 1.],\n",
              "       [0., 0., 1., 1., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The StringLookup Layer\n"
      ],
      "metadata": {
        "id": "jYON_t73w0e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n",
        "str_lookup_layer = tf.keras.layers.StringLookup()\n",
        "str_lookup_layer.adapt(cities)\n",
        "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]]) # unknown = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u58xBu4xwhaw",
        "outputId": "0d716104-d00c-43f6-ce7f-bd38191d6d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
              "array([[1],\n",
              "       [3],\n",
              "       [3],\n",
              "       [0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_lookup_layer = tf.keras.layers.StringLookup(num_oov_indices=5)\n",
        "str_lookup_layer.adapt(cities)\n",
        "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Foo\"], [\"Bar\"], [\"Baz\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHzMnVaGw7FM",
        "outputId": "da96b3cd-38ef-4cf1-bd0e-f0ea97473b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[5],\n",
              "       [7],\n",
              "       [4],\n",
              "       [3],\n",
              "       [4]])>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_lookup_layer = tf.keras.layers.StringLookup(output_mode=\"one_hot\")\n",
        "str_lookup_layer.adapt(cities)\n",
        "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tgvxfR_xDv_",
        "outputId": "570b8eb6-02fb-4e93-85a5-434422d9994e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\n",
              "array([[0, 1, 0, 0],\n",
              "       [0, 0, 0, 1],\n",
              "       [0, 0, 0, 1],\n",
              "       [1, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [123, 456, 789]\n",
        "int_lookup_layer = tf.keras.layers.IntegerLookup()\n",
        "int_lookup_layer.adapt(ids)\n",
        "int_lookup_layer([[123], [456], [123], [111]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj43f9onxLQ0",
        "outputId": "b4cf13f2-244c-4e49-8a2d-1148b267a4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
              "array([[3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Hashing Layer\n"
      ],
      "metadata": {
        "id": "PfkyAqMfxWY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hashing_layer = tf.keras.layers.Hashing(num_bins=10)\n",
        "hashing_layer([[\"Paris\"], [\"Tokyo\"], [\"Auckland\"], [\"Montreal\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBtK7v3FxRrc",
        "outputId": "e81d5784-20c1-4db7-fe8e-9440ffaec24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
              "array([[0],\n",
              "       [1],\n",
              "       [9],\n",
              "       [1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical Features Using Embeddings\n"
      ],
      "metadata": {
        "id": "NeWfHxZ7xgST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=5, output_dim=2)\n",
        "embedding_layer(np.array([2, 4, 2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCwxTao7xZpU",
        "outputId": "1e724f41-cfff-44cd-81a6-702f2a2ac823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[ 0.02497954, -0.01118562],\n",
              "       [-0.01516532, -0.0354758 ],\n",
              "       [ 0.02497954, -0.01118562]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "ocean_prox = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "str_lookup_layer = tf.keras.layers.StringLookup()\n",
        "str_lookup_layer.adapt(ocean_prox)\n",
        "lookup_and_embed = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=[], dtype=tf.string),  # WORKAROUND\n",
        "    str_lookup_layer,\n",
        "    tf.keras.layers.Embedding(input_dim=str_lookup_layer.vocabulary_size(),\n",
        "                              output_dim=2)\n",
        "])\n",
        "lookup_and_embed(np.array([\"<1H OCEAN\", \"ISLAND\", \"<1H OCEAN\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRk6XuLyxoLB",
        "outputId": "26847e24-57e3-4cfb-9e70-41982f918848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[-0.03695794, -0.01946068],\n",
              "       [-0.00500988,  0.04776471],\n",
              "       [-0.03695794, -0.01946068]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing\n"
      ],
      "metadata": {
        "id": "oXP73dbEykCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"Be, be, be.\"]\n",
        "text_vec_layer = tf.keras.layers.TextVectorization()\n",
        "text_vec_layer.adapt(train_data)\n",
        "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwTl1URfymwx",
        "outputId": "4a20e229-f2f5-42fe-a844-468e2062216e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
              "array([[2, 1, 0, 0],\n",
              "       [6, 2, 1, 2]])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
        "text_vec_layer.adapt(train_data)\n",
        "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO3t63dezOIp",
        "outputId": "68e20360-74db-4552-c2b9-f4501d16daaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[2, 1], [6, 2, 1, 2]]>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")\n",
        "text_vec_layer.adapt(train_data)\n",
        "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PosWoksezYJ7",
        "outputId": "401ad9b9-abae-409c-ec66-65126d150c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
              "array([[0.96725637, 0.6931472 , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.96725637, 1.3862944 , 0.        , 0.        , 0.        ,\n",
              "        1.0986123 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pretrained Language Model Components\n"
      ],
      "metadata": {
        "id": "ApO_iGwlzjZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\")\n",
        "sentence_embeddings = hub_layer(tf.constant([\"To be\", \"Not to be\"]))\n",
        "sentence_embeddings.numpy().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3uZMBfCzc9x",
        "outputId": "82f0fa61-5905-47fe-e05f-38acc9b39b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.25,  0.28,  0.01,  0.1 ,  0.14,  0.16,  0.25,  0.02,  0.07,\n",
              "         0.13, -0.19,  0.06, -0.04, -0.07,  0.  , -0.08, -0.14, -0.16,\n",
              "         0.02, -0.24,  0.16, -0.16, -0.03,  0.03, -0.14,  0.03, -0.09,\n",
              "        -0.04, -0.14, -0.19,  0.07,  0.15,  0.18, -0.23, -0.07, -0.08,\n",
              "         0.01, -0.01,  0.09,  0.14, -0.03,  0.03,  0.08,  0.1 , -0.01,\n",
              "        -0.03, -0.07, -0.1 ,  0.05,  0.31],\n",
              "       [-0.2 ,  0.2 , -0.08,  0.02,  0.19,  0.05,  0.22, -0.09,  0.02,\n",
              "         0.19, -0.02, -0.14, -0.2 , -0.04,  0.01, -0.07, -0.22, -0.1 ,\n",
              "         0.16, -0.44,  0.31, -0.1 ,  0.23,  0.15, -0.05,  0.15, -0.13,\n",
              "        -0.04, -0.08, -0.16, -0.1 ,  0.13,  0.13, -0.18, -0.04,  0.03,\n",
              "        -0.1 , -0.07,  0.07,  0.03, -0.08,  0.02,  0.05,  0.07, -0.14,\n",
              "        -0.1 , -0.18, -0.13, -0.04,  0.15]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Datasets\n"
      ],
      "metadata": {
        "id": "D83lfZw3z0ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "datasets = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
        "mnist_train, mnist_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "5560d688bca942ccb41baf2251ae7a21",
            "c9ea8d1e80874ad282e767af6255ef60",
            "815e710e4f74461e8271da66dbf863d1",
            "26b53504d9d843e8b19b874251c73fa2",
            "0ec2b7a8480e481896c12c59cd75f8c8",
            "3d169cc281a846ab883b551aae5f28c8",
            "5f97f154c59d4d36ae0bbc55353ac36c",
            "9e1c99005a7a4fd48e8377197bf23af2",
            "8ae5ecf517394bdabb6e53cf897de938",
            "88cd0db5d4c84f5fb11d6fb1beb906dc",
            "5b02d642f9d94f32ad2f7edf6212b6c3"
          ]
        },
        "id": "LDk92LSuzrq1",
        "outputId": "fb1d399a-c337-4e2a-a493-0d11ee2ed4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5560d688bca942ccb41baf2251ae7a21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>,\n",
              " <_PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in mnist_train.shuffle(10_000, seed=42).batch(32).prefetch(1):\n",
        "    images = batch[\"image\"]\n",
        "    labels = batch[\"label\"]\n",
        "    # [...] do something with the images and labels"
      ],
      "metadata": {
        "id": "N_gPwn0Tz-Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.shuffle(10_000, seed=42).batch(32)\n",
        "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ],
      "metadata": {
        "id": "xA9VU9qt0Gsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, valid_set, test_set = tfds.load(\n",
        "    name=\"mnist\",\n",
        "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
        "    as_supervised=True\n",
        ")\n",
        "train_set = train_set.shuffle(10_000, seed=42).batch(32).prefetch(1)\n",
        "valid_set = valid_set.batch(32).cache()\n",
        "test_set = test_set.batch(32).cache()\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=5)\n",
        "test_loss, test_accuracy = model.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmcgKMPe0M1F",
        "outputId": "b13f25d8-4f75-41dd-afc2-1948c15cbdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7525 - loss: 19.6116 - val_accuracy: 0.8795 - val_loss: 6.0743\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 5.7905 - val_accuracy: 0.8850 - val_loss: 5.7786\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 5.1527 - val_accuracy: 0.8750 - val_loss: 6.0847\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 4.9867 - val_accuracy: 0.8858 - val_loss: 5.8824\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 4.8105 - val_accuracy: 0.8815 - val_loss: 5.9809\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 5.5508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9sWuqph0ZPv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}